Reviewer 1: 



Reviewer 2
I believe the paper contains very good and interesting results, but it needs a revision before being published.

Pros: I really like the main idea of the paper: using the machinery of moves that allows one to efficiently recompute the R=DV decomposition after one cyclic permutation in the input filtration, the authors find a heuristic to decompose an arbitrary permutation of the filtration into a sequence of moves of provably minimal length and small cost (this is the heuristic part). The authors show experimentally that this idea works. The paper is as self-contained as possible and the authors work out some concrete examples which are helpful to the reader.

Cons: The detailed list of the remarks follows. Sorry, it’s not ordered by importance, so there are trivial things like grammar/typos and more serious issues.
 In general, I feel that the paper is a bit too verbose - it can be made shorter without losing virtually any content.
The most important issues that are listed below are: the comment about ‘MoveLeft’ and some missing (or hard to find) details about the algorithm (GreedySchedule in Alg. 1).
Also, I would appreciate if the authors formulated  exactly what is the implementation they used in their experiments (e.g., did they really use treaps?).


----

Point by point responses: 

Page 1, abstract: I don’t understand the $O(m \log \log m)$ estimate here. According to Thm. 1, this is the time it takes just to find $d$, the length of the optimal schedule. Computing the schedule itself costs $O(dm \log m)$ or $O(m \log m)$ per update. Shouldn’t this be in the abstract? Also, why ‘simulation of persistence’ (this expression will appear below, too)?

* - Yes, the $O(m \log \log m)$ complexity refers to the complexity of finding the length of the schedule and the LIS (only). We leave out the complexity of constructing the schedule itself in the abstract as we envision there are situations where the algorithm used to actually construct the schedule may vary---depending on the particular data structure of choice supporting the operations outlined in 3.3 (e.g. implicit treaps, segment tree, vEB tree), the deterministic and expected time complexity may change.

Page 4, 'if the relations are available a-priori' – do the authors mean ‘edges’?

- Yes. 

Page 7, ‘we summarize our main results (Theorem 1)’. The main claim in theorem 1 is that one can efficiently compute only the length of the optimal schedule. Will the authors consider reorganizing?

- see above. 

Page 8: Although $d$ can be  $O(m)$, we provide evidence that $d ~ m - sqrt(m)$. Well, $m - \sqrt(m)  = O(m)$, why ‘although’? Should it be ‘Although d can be O(m) and we provide evidence that d ~ m - sqrt(m), d is much smaller in practice’?

- Yes, as the previous reviewers also pointed out, we aware that $m - \sqrt(m)  = O(m)$, which is why we omitted the big-O in the notation $d ~ m - sqrt(m)$. To remedy this, we amended the statement to clarify. 

Page 8: ‘an simplexwise’ -> a simplexwise

- fixed. 

Page 9: I am more used to the ‘positive/negative simplex’ terminology than ‘creator/destroyer’.
This is a matter of personal preference, of course.

- 

Page 10: ‘Despite this high algorithmic complexity, the number of column operations has been observed to be super-linear in practice’ – this has to be rephrased, because there is no contradiction (order of m^2 column operations is super-linear, too).

- TODO: cite ripser

Sec. 2.3, Moves. Sorry, it might be my fault but I had difficulty understanding the procedure from the description. I believe having the pseudocode right here will be helpful (after I read it in the appendix, I was happy with the algorithm). Especially since the algorithm is needed in the proof of Prop. 2, too.

- We previously moved much of pseudocode to the appendix in order to streamline the presentation of the concepts, as the pseudocode for both algorithms takes up an entire page (and the pseudocode for MoveRight is also available in Busaryev's paper). We have moved them back. 
(todo: fix?) 

Page 16, Alg. 1. 
a) The authors say ‘Algorithm 1 may be easily modified to be completely online, keeping at most two filtrations and one decomposition in memory’. I agree, but I believe it would be equally easy and more natural to state it in this form immediately. The change is in modifying the meaning of \rho_i: while now it is the permutation taking f_1 to f_i, it should be replaced with the permutation taking f_{i-1} to f_i.

- The algorithm is now presented in the much simpler "online form", which only requires as input a pair of filtrations and a single D = RV decomposition. The original batch-processing presentation of pseudocode reflected more closely the implementation we used (we found it more efficient to compute a batch of schedules, concatenate them, and then give them to the moving algorithm to process sequentially, saving the diagrams between each schedule execution).

b) Is it correct that the authors use both MoveRight and MoveLeft in their implementation? I believe it is necessary, and Alg. 1 reflects that; however, it raises some questions about the sequel. I’ll get back to this point.

- Yes! 

c) Line 6 calls the function GreedySchedule. There is no such algorithm in the paper. There is Alg. 5 in the appendix, LCS-sort, but there is no greedy heuristic in it. Also, it computes the LIS internally, while GreedySchedule takes the longest increasing sequence as a second argument. Please fix this.

- The GreedySchedule algorithm wasn't included in part because it corresponds to simply modifying line 6 in Alg. 5 (choosing the next 'symbol'/simplex to move) with equation (22).
(todo: mention this or actually build out the pseudocode for 3.4.2)   (TODO... make it explicit)

Page 17, the paragraph after Def. 1: ‘the former can be that can be solved optimally’ - this sentence should be fixed.

- Fixed. 

Page 19: ‘small changes … affects’ -> affect.

- Fixed 

Note that $m_{i,j}$ is defined here and used in Alg. 5 at the very end of the paper without explanation.

- The usage in Alg. 5 was intentional as it defined in equations (10) and (11); a reference to those equations has been added in Alg. 5. 

Page 20: ‘allows use to exploit’ -> allows us to exploit

- Fixed. 

Page 21: Do I understand correctly that this is what is going on in the proof of Corollary 1: $E(m - |LCS(p, q)|) = m - 2 \sqrt(m) - cm^{⅙} + o(m^{⅙})$ by the known result of Baik for $E|LIS(p)|$, therefore it is less than $m - \sqrt(m)$ ? So any function which is asymptotically less than $ 2 \sqrt(m) - cm^{⅙} + o(m^{⅙} $ would do? Another question : Corollary 1 speaks about two random filtrations, which the authors interpret as ‘two permutations chosen uniformly at random’ (explaining why this is okay in light of Boissonat’s result). But the longest increasing sequence result by Baik is for a single permutation drawn uniformly at random. Is it obvious that, if p and q are drawn from S_m uniformly at random, then $p \circ q^{-1}$ (the permutation we should consider for LIS) is also uniformly distributed? Well, for symmetry reasons it seems to be true and obvious, but, given the level of details in the other parts of the paper, the authors may want to include this as well.

- We agree that $p \circ q^{-1}$ is uniform, and we agree the proof strategy for Corollary 1 outlined by the reviewer would match the level of detail of the rest of the paper. That said, in our struggle to keep the length of the paper manageable we chose to present the proof in a succinct and informal way. 

Page 22, ‘It is clear from Corollary 1’ -  wrong reference. Probably, from the proof of proposition 3 (Prop. 3 itself does not say anything about LIS).

- Yes, this used to be its own corollary. The proof of prop 3 is indeed the reduction we're referring too. We've amended the statement to explicitly point to the proof.  

Let T denote a ordered set-like -> an ordered set-like

- Fixed. 

Page 27: equation (22) may solved  -> equation (22) can be solved

- Fixed. 

General comment on the greedy heuristic: does most of the reasoning in section 3.4 apply to the case of MoveRight only? The starting point is the term \sum |I_k| + |J_k|, which only applies to moving simplex i to simplex j if i < j. What about the MoveLeft? Can it be analyzed theoretically? Does it occur frequently in the authors’ experiments? Can the freedom that the authors have in choosing the schedule of the optimal length be used to minimize the number of left moves and, if I want to implement this approach, should I do that or would it only harm me?

- We actually included a discussion and small analysis of MoveLeft, including some empirical comparisons, in the original draft of the page. To answer your questions successively: 

* "does most of the reasoning ... apply to the case of MoveRight only?"

	- Yes, due to theoretical limitations, the statement only holds for MoveRight. 

* "What about the MoveLeft? Can it be analyzed theoretically?"
	
	- We have a small discussion of MoveLeft in the appendix. We left out 
	Our internal 

Sec. 4.1: I find the phrase ‘simulate persistence’ unusual. Does it just mean ‘compute persistent homology’? As for the second test (page 28): was the Algorithm 1 used verbatim, or was the scheduling performed to move from one snapshot to the next one?

Page 32, 4.3.1:  Is  \kappa from [10] the same as defined in Theorem 1? I suspect not, [10] says it’s coarseness. Please clarify.

Page 34: ‘they a convenient basis for D may be obtained’ - is this supposed to be ‘they prove that a convenient basis …’ ?
voronoi  -> Voronoi
7-spheres volume -> 7-sphere’s volume
In order reveal -> In order to reveal

Page 35: ‘Projecting the image data onto the first two basis vectors of leads’ - basis vectors of what?

Page 36: ‘the number of permutations applied throughout the encountered along the traversal of the dual graph’ - please fix this sentence.
vineyards is, moves requires -> either ‘vineyards/moves algorithm/approach is/requires’, or ‘vineyards are/moves require’. Or make vineyards and moves boldface or italics, then they are visually perceived as names.
that naively computing -> than naively computing

Page 37: if the filtrations in the parameterization family is nearby -> are nearby

Page 43 , A1.1.1 'After setting V is set' -> After setting V
'Since there exists complexes' -> Since there exists a complex / there exist complexes

Page 45. We recall an important claim .. - What is the claim? Seems to be missing, it should say something about positive/negative simplices.

Page 48. Well, in A.2.1 the authors mention \kappa as coarseness parameter! Also, the naming clash between the structure T used to compute the sorting and the barcode template T is unfortunate.

kendall -> Kendall







-----

readability - We switched the notation from symbol to permutations / indices in section 3.4, and we've reworked the pseudocode ; symbols 
on the overhead of moves - we agree that the figures may seem misleading; future work, output / geometry sensitive . Talk about balance the fraction  of kendall distances
assessment - talk abotu vineyards and non-trivial implementation details; it woudl portray vineyards inaccuractely 

Figure 1 - fixed with upper level set filtration or equiv lower filtatratin with 1 - intensity 









